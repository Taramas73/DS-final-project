{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgw0NKEXkHNtLQMtp5Nha1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taramas73/DS-final-project/blob/irusha/Hybrid_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Hybrid Model: EfficientNet Encoder + U-Net Decoder\n",
        "Here's how you can implement this architecture:"
      ],
      "metadata": {
        "id": "lZZ6doNF8NDE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TXctj-Hm8GFE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, BatchNormalization, Activation, Concatenate\n",
        "\n",
        "def build_efficient_unet(input_shape=(256, 256, 3), n_classes=1):\n",
        "    # Input layer\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # EfficientNet encoder (pre-trained)\n",
        "    base_model = EfficientNetB0(include_top=False, weights='imagenet', input_tensor=inputs)\n",
        "\n",
        "    # Get specific activation layers from EfficientNet\n",
        "    # These will be used for skip connections\n",
        "    s1 = base_model.get_layer('block2a_expand_activation').output  # 128x128\n",
        "    s2 = base_model.get_layer('block3a_expand_activation').output  # 64x64\n",
        "    s3 = base_model.get_layer('block4a_expand_activation').output  # 32x32\n",
        "    s4 = base_model.get_layer('block6a_expand_activation').output  # 16x16\n",
        "\n",
        "    # Bridge\n",
        "    b1 = base_model.get_layer('top_activation').output  # 8x8\n",
        "\n",
        "    # Decoder path\n",
        "    # Upsampling block 1\n",
        "    d1 = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(b1)\n",
        "    d1 = BatchNormalization()(d1)\n",
        "    d1 = Activation('relu')(d1)\n",
        "    d1 = Concatenate()([d1, s4])\n",
        "    d1 = Conv2D(256, (3, 3), padding='same')(d1)\n",
        "    d1 = BatchNormalization()(d1)\n",
        "    d1 = Activation('relu')(d1)\n",
        "\n",
        "    # Upsampling block 2\n",
        "    d2 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(d1)\n",
        "    d2 = BatchNormalization()(d2)\n",
        "    d2 = Activation('relu')(d2)\n",
        "    d2 = Concatenate()([d2, s3])\n",
        "    d2 = Conv2D(128, (3, 3), padding='same')(d2)\n",
        "    d2 = BatchNormalization()(d2)\n",
        "    d2 = Activation('relu')(d2)\n",
        "\n",
        "    # Upsampling block 3\n",
        "    d3 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(d2)\n",
        "    d3 = BatchNormalization()(d3)\n",
        "    d3 = Activation('relu')(d3)\n",
        "    d3 = Concatenate()([d3, s2])\n",
        "    d3 = Conv2D(64, (3, 3), padding='same')(d3)\n",
        "    d3 = BatchNormalization()(d3)\n",
        "    d3 = Activation('relu')(d3)\n",
        "\n",
        "    # Upsampling block 4\n",
        "    d4 = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(d3)\n",
        "    d4 = BatchNormalization()(d4)\n",
        "    d4 = Activation('relu')(d4)\n",
        "    d4 = Concatenate()([d4, s1])\n",
        "    d4 = Conv2D(32, (3, 3), padding='same')(d4)\n",
        "    d4 = BatchNormalization()(d4)\n",
        "    d4 = Activation('relu')(d4)\n",
        "\n",
        "    # Final upsampling\n",
        "    d5 = Conv2DTranspose(16, (3, 3), strides=(2, 2), padding='same')(d4)\n",
        "    d5 = BatchNormalization()(d5)\n",
        "    d5 = Activation('relu')(d5)\n",
        "\n",
        "    # Output layer\n",
        "    if n_classes == 1:  # Binary segmentation\n",
        "        outputs = Conv2D(1, (1, 1), activation='sigmoid')(d5)\n",
        "    else:  # Multi-class segmentation\n",
        "        outputs = Conv2D(n_classes, (1, 1), activation='softmax')(d5)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Freeze the encoder weights initially\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    return model"
      ]
    }
  ]
}